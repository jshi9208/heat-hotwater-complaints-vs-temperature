{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":55,"metadata":{"id":"emu6a5t9GkU9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684433944765,"user_tz":240,"elapsed":1381,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}},"outputId":"921f53ec-b339-44d4-ea83-650343fcf398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Authenticated\n","The google.cloud.bigquery extension is already loaded. To reload it, use:\n","  %reload_ext google.cloud.bigquery\n","The google.colab.data_table extension is already loaded. To reload it, use:\n","  %reload_ext google.colab.data_table\n"]}],"source":["from google.colab import auth\n","auth.authenticate_user()\n","print('Authenticated')\n","\n","\n","# Google Colab load modules for BigQuery\n","%load_ext google.cloud.bigquery\n","%load_ext google.colab.data_table\n"]},{"cell_type":"code","source":["# ETL Weather  Facts\n","# If using the native Google BigQuery API module:\n","from google.cloud import bigquery\n","from google.cloud.exceptions import NotFound\n","# import credentials\n","import pandas as pd\n","import os\n","import pyarrow\n","import logging\n","from datetime import datetime"],"metadata":{"id":"-0lcptslG0xp","executionInfo":{"status":"ok","timestamp":1684433944766,"user_tz":240,"elapsed":10,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame\n","# Set the name of the fact table\n","fact_name = 'weather'\n","\n","# Set the GCP Project, dataset and table name\n","gcp_project = 'cis4400project-384418'\n","bq_dataset = 'weather_dw'\n","table_name = fact_name + '_fact'\n","# Construct the full BigQuery path to the table\n","fact_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n","file_source_path = '/content'"],"metadata":{"id":"nLbCuFQYG04c","executionInfo":{"status":"ok","timestamp":1684433944767,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Set up logging\n","for handler in logging.root.handlers[:]:\n","    logging.root.removeHandler(handler)\n","current_date = datetime.today().strftime('%Y%m%d')\n","log_filename = \"_\".join([\"etl\",table_name,current_date])+\".log\"\n","logging.basicConfig(filename=log_filename, encoding='utf-8', format='%(asctime)s %(message)s', level=logging.DEBUG)\n","logging.info(\"=========================================================================\")\n","logging.info(f\"Starting ETL Run for {table_name} on date {current_date}\")"],"metadata":{"id":"f0VxlZ5FG067","executionInfo":{"status":"ok","timestamp":1684433944768,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["def load_csv_data_file(logging, file_source_path, file_name, df):\n","    \"\"\"\n","    load_csv_data_file\n","    Accepts a file source path and a file name\n","    Loads the file into a data frame\n","    Exits the program on error\n","    Returns the dataframe\n","    \"\"\"\n","    file_source = os.path.join(file_source_path, file_name)\n","    logging.info(\"Reading source data file: %s\",file_source)\n","    # Read in the source data file for the customers data\n","    try:\n","        df = pd.read_csv(file_source)\n","        # Set all of the column names to lower case letters\n","        df = df.rename(columns=str.lower)\n","        logging.info(\"Read %d records from source data file: %s\",df.shape[0],file_source)\n","        return df\n","    except:\n","        logging.error(f\"Failed to read file: {file_source}\")\n","        # os._exit(-1)\n","    return df"],"metadata":{"id":"VBLZP2dgG088","executionInfo":{"status":"ok","timestamp":1684433944768,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def transform_data(logging, df):\n","    \"\"\"\n","    transform_data\n","    Accepts a data frame\n","    Performs any specific cleaning and transformation steps on the dataframe\n","    Returns the modified dataframe\n","    \"\"\"    \n","    # Convert the date_of_birth to a datetime64 data type. 2012-08-21 04:12:16.827\n","    logging.info(\"Managing data types.\")\n","    df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], format='%m/%d/%Y')\n","    # Convert the postal code into a string\n","    df['postal_code'] =  df['postal_code'].astype(str)\n","    return df"],"metadata":{"id":"c0mBR0-YG0_I","executionInfo":{"status":"ok","timestamp":1684433944768,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["def create_bigquery_client(logging):\n","    \"\"\"\n","    create_bigquery_client\n","    Creates a BigQuery client using the path to the service account key file\n","    for credentials.\n","    Returns the BigQuery client object\n","    \"\"\"\n","    try:\n","        # bqclient = bigquery.Client.from_service_account_json(credentials.path_to_service_account_key_file)\n","        bqclient = bigquery.Client(gcp_project)        \n","        logging.info(f\"Created BigQuery Client: {bqclient}\")\n","        return bqclient\n","    except Exception as err:\n","        logging.error(\"Failed to create BigQuery Client.\", err)\n","        # os._exit(-1)\n","    return bqclient"],"metadata":{"id":"GKKpK0r9G1Ct","executionInfo":{"status":"ok","timestamp":1684433944768,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["def upload_bigquery_table(logging, bqclient, table_path, write_disposition, df):\n","    \"\"\"\n","    upload_bigquery_table\n","    Accepts a path to a BigQuery table, the write disposition and a dataframe\n","    Loads the data into the BigQuery table from the dataframe.\n","    for credentials.\n","    The write disposition is either\n","    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.   \n","    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n","    \"\"\"\n","    try:\n","        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n","        # Submit the job\n","        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)  \n","        # Show the job results\n","        job.result()\n","    except Exception as err:\n","        logging.error(\"Failed to load BigQuery Table.\", err)\n","        # os._exit(-1)\n"],"metadata":{"id":"LPZm5qW0G1FT","executionInfo":{"status":"ok","timestamp":1684433944769,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["def bigquery_table_exists(table_path, bqclient):\n","    \"\"\"\n","    bigquery_table_exists\n","    Accepts a path to a BigQuery table\n","    Checks if the BigQuery table exists.\n","    Returns True or False\n","    \"\"\"    \n","    try:\n","        bqclient.get_table(table_path)  # Make an API request.\n","        return True\n","    except NotFound:\n","        # print(\"Table {} is not found.\".format(table_id))\n","        return False"],"metadata":{"id":"STCp6cP8G1HY","executionInfo":{"status":"ok","timestamp":1684433944769,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def query_bigquery_table(logging, table_path, bqclient, surrogate_key):\n","    \"\"\"\n","    query_bigquery_table\n","    Accepts a path to a BigQuery table and the name of the surrogate key\n","    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n","    Returns the dataframe\n","    \"\"\"    \n","    bq_df = pd.DataFrame\n","    # sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n","    sql_query = 'SELECT * FROM `' + table_path + '`'\n","    logging.info(\"Running query: %s\", sql_query)\n","    bq_df = bqclient.query(sql_query).to_dataframe()\n","    return bq_df"],"metadata":{"id":"c9V3n4k9G1Jb","executionInfo":{"status":"ok","timestamp":1684433944769,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["def add_surrogate_key(df, dimension_name='customers', offset=1):\n","    \"\"\"\n","    add_surrogate_key  \n","    Accepts a data frame and inserts an integer identifier as the first column\n","    Returns the modified dataframe\n","    \"\"\"\n","    # Reset the index\n","    df.reset_index(drop=True, inplace=True)\n","    # Add the new surrogate key starting from offset\n","    df.insert(0, dimension_name+'_dim_id', df.index+offset)\n","    return df"],"metadata":{"id":"JHLjiGzwG1Lg","executionInfo":{"status":"ok","timestamp":1684433944769,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["def add_update_date(df, current_date):\n","    \"\"\"\n","    add_update_date\n","    Accepts a data frame and inserts the current date as a new field\n","    Returns the modified dataframe\n","    \"\"\"\n","    df['update_date'] = pd.to_datetime(current_date)\n","    return df"],"metadata":{"id":"J4A3YljaG1Nm","executionInfo":{"status":"ok","timestamp":1684433944770,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["def add_update_timestamp(df):\n","    \"\"\"\n","    add_update_timestamp\n","    Accepts a data frame and inserts the current datetime as a new field\n","    Returns the modified dataframe\n","    \"\"\"\n","    df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n","    return df"],"metadata":{"id":"81Zhr8wpG1P3","executionInfo":{"status":"ok","timestamp":1684433944770,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["def build_new_table(logging, bqclient, table_path, df):\n","    \"\"\"\n","    build_new_table\n","    Accepts a path to a dimensional table, the dimension name and a data frame \n","    Add the surrogate key and a record timestamp to the data frame\n","    Inserts the contents of the dataframe to the dimensional table.\n","    \"\"\"\n","    logging.info(\"Target table %s does not exit\", table_path)\n","    upload_bigquery_table(logging, bqclient, table_path, \"WRITE_TRUNCATE\", df)"],"metadata":{"id":"QUmCtA09G1SJ","executionInfo":{"status":"ok","timestamp":1684433944770,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["def insert_existing_table(logging, bqclient, table_path, df):\n","    \"\"\"\n","    insert_existing_table\n","    Accepts a path to a dimensional table, the dimension name and a data frame \n","    Compares the new data to the existing data in the table.\n","    Inserts the new/modified records to the existing table\n","    \"\"\"\n","    logging.info(\"Target table %s exits. Appending records.\", table_path)\n","    upload_bigquery_table(logging, bqclient, table_path, \"WRITE_APPEND\", df)"],"metadata":{"id":"5S7Uab20G1UX","executionInfo":{"status":"ok","timestamp":1684433944770,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def dimension_lookup(logging, dimension_name='date', lookup_columns=['wdate'], df=df):\n","    \"\"\"\n","    dimension_lookup\n","    Lookup the lookup_columns in the dimension_name and return the associated surrogate keys\n","    Returns dataframe augmented with the surrogate keys\n","    \"\"\"\n","    bq_df = pd.DataFrame\n","    logging.info(\"Lookup dimension %s.\", dimension_name)\n","    surrogate_key = dimension_name+\"_dim_id\"\n","    dimension_table_path = \".\".join([gcp_project,bq_dataset,dimension_name+\"_dimension\"])\n","    # Fetch the existing table\n","    bq_df = query_bigquery_table(logging, dimension_table_path, bqclient, surrogate_key)\n","    print(bq_df)\n","    # Melt the dimension dataframe into an index with the lookup columns\n","    m = bq_df.melt(id_vars=lookup_columns, value_vars=surrogate_key)\n","    # print(m)\n","    # Rename the \"value\" column to the surrogate key column name\n","    m=m.rename(columns={\"value\":surrogate_key})\n","    # Merge with the fact table record\n","    df = df.merge(m, on=lookup_columns, how='left')\n","    # Drop the \"variable\" column and the lookup columns\n","    df = df.drop(columns=lookup_columns)\n","    df = df.drop(columns=\"variable\")\n","    return df"],"metadata":{"id":"77XmJEulG1Wl","executionInfo":{"status":"ok","timestamp":1684433944771,"user_tz":240,"elapsed":12,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["def date_dimension_lookup(logging, dimension_name='date', lookup_column='create_date', df=df):\n","    \"\"\"\n","    dimension_lookup\n","    Lookup the lookup_columns in the dimension_name and return the associated surrogate keys\n","    Returns dataframe augmented with the surrogate keys\n","    \"\"\"\n","    bq_df = pd.DataFrame\n","    logging.info(\"Lookup date dimension on column %s.\", lookup_column)\n","    surrogate_key = dimension_name+\"_dim_id\"\n","    dimension_table_path = \".\".join([gcp_project,bq_dataset,dimension_name+\"_dimension\"])\n","    # Fetch the existing table\n","    bq_df = query_bigquery_table(logging, dimension_table_path, bqclient, surrogate_key)\n","    bq_df[\"full_date\"] = pd.to_datetime(bq_df.full_date, format=\"%m/%d/%Y\")\n","    # Return just the date portion\n","    bq_df[\"full_date\"] = bq_df.full_date.dt.date\n","    \n","    # Extract the date from 'created_date' column\n","    df[lookup_column] = pd.to_datetime(df[lookup_column], format=\"%m/%d/%Y\")\n","    # Strip off the time portion\n","    df[lookup_column+\"_time\"] = df[lookup_column].dt.strftime(\"%H:%M:%S\")\n","    # Return just the date portion\n","    df[lookup_column] = df[lookup_column].dt.date\n","    \n","    # Melt the dimension dataframe into an index with the lookup columns\n","    m = bq_df.melt(id_vars='full_date', value_vars=surrogate_key)\n","    # Rename the \"value\" column to the surrogate key column name\n","    m=m.rename(columns={\"value\":lookup_column+\"_dim_id\"})\n","    \n","    # Merge with the fact table record on the created_date\n","    df = df.merge(m, left_on=lookup_column, right_on='full_date', how='left')\n","\n","    # Drop the \"variable\" column and the lookup columns\n","    df = df.drop(columns=lookup_column)\n","    df = df.drop(columns=\"variable\")\n","    df = df.drop(columns=\"full_date\")\n","    return df"],"metadata":{"id":"S8lW_5u0G1Yz","executionInfo":{"status":"ok","timestamp":1684433944771,"user_tz":240,"elapsed":11,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\": \n","    df = pd.DataFrame\n","    # Create the BigQuery Client\n","    bqclient = create_bigquery_client(logging)\n","    # Load in the data file\n","    # df = load_csv_data_file(logging, file_source_path, \"weather_data_5_boroughs_daily.csv\", df)\n","    df = load_csv_data_file(logging, file_source_path, \"weather_data_5_boroughs_daily_2.csv\", df)\n","    # print(df)\n","\n","    # If city is empty, fill it in with NEW YORK\n","    ##df.city = df.city.fillna('NEW YORK')\n","    # Consider removing columns that we will never use  df.drop([....])\n","\n","    # Lookup the agency dimension record  agency_dim_id\n","    #df = dimension_lookup(logging, dimension_name='agency', lookup_columns=['agency', 'agency_name'], df=df)\n","    # df = load_csv_data_file(logging, file_source_path, \"weather_data_5_boroughs_daily.csv\", df)\n","    # print(df)\n","    # Lookup the location dimension record  location_dim_id\n","    df = dimension_lookup(logging, dimension_name='location', lookup_columns=['borough', 'city', 'state', 'zipcode'], df=df)\n","    df = date_dimension_lookup(logging, dimension_name='date', lookup_column='wdate', df=df)\n","\n","    # print(df)\n","\n","    # A list of all of the surrogate keys and columns we will keep\n","    surrogate_keys=['location_dim_id','wdate_dim_id','temperature_max','temperature_avg','temperature_m']\n","\n","    # Remove all of the other non-surrogate key columns\n","    df = df[surrogate_keys]\n","\n","    # See if the target table exists\n","    target_table_exists = bigquery_table_exists(fact_table_path, bqclient )\n","    # If the target table does not exist, load all of the data into a new table\n","    if not target_table_exists:\n","        build_new_table(logging, bqclient, fact_table_path, df)\n","    # If the target table exists, then perform an incremental load    \n","    if target_table_exists:\n","        insert_existing_table(logging, bqclient, fact_table_path, df)"],"metadata":{"id":"NUahAaCzG1ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684433953614,"user_tz":240,"elapsed":8854,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}},"outputId":"faddda8c-6af2-4a61-bf5b-1d90f0d9b84d"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["   location_dim_id  latitude  longitude        borough              city  \\\n","0                1   40.8616   -73.8809          Bronx  Botanical Garden   \n","1                2   40.6215   -74.0096       Brooklyn     Dyker Heights   \n","2                3   40.7638   -73.9918      Manhattan          New York   \n","3                4   40.7557   -73.8831         Queens   Jackson Heights   \n","4                5   40.5674   -74.1343  Staten Island      Richmondtown   \n","5                6   40.5674   -74.1343  Staten Island      Richmondtown   \n","\n","  state  zipcode          update_timestamp  \n","0    NY    10458 2023-05-18 16:20:19+00:00  \n","1    NY    11228 2023-05-18 16:20:19+00:00  \n","2    NY    10018 2023-05-18 16:20:19+00:00  \n","3    NY    11372 2023-05-18 16:20:19+00:00  \n","4    NY    10306 2023-05-18 16:20:19+00:00  \n","5    NY    10308 2023-05-18 16:20:19+00:00  \n"]}]},{"cell_type":"code","source":["!tail  -45  etl__weather_fact_20230515.log"],"metadata":{"id":"SxbGvvKPG1dk","executionInfo":{"status":"ok","timestamp":1684433953800,"user_tz":240,"elapsed":206,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab02b964-652f-4f51-f22b-e43667c7bb62"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["tail: cannot open 'etl__weather_fact_20230515.log' for reading: No such file or directory\n"]}]}]}