{"cells":[{"cell_type":"code","execution_count":215,"id":"cfa00868","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfa00868","outputId":"b2227742-a7ef-4a2a-dc52-946b3424631a","executionInfo":{"status":"ok","timestamp":1682795972847,"user_tz":240,"elapsed":323,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Authenticated\n"]}],"source":["from google.colab import auth\n","auth.authenticate_user()\n","print('Authenticated')\n"]},{"cell_type":"code","source":[" # Google Colab load modules for BigQuery\n","%load_ext google.cloud.bigquery\n","%load_ext google.colab.data_table"],"metadata":{"id":"8fEahS8G3Cjv","executionInfo":{"status":"ok","timestamp":1682795972848,"user_tz":240,"elapsed":8,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6adb2487-a1a3-4567-bcde-38362ce45a4e"},"id":"8fEahS8G3Cjv","execution_count":216,"outputs":[{"output_type":"stream","name":"stdout","text":["The google.cloud.bigquery extension is already loaded. To reload it, use:\n","  %reload_ext google.cloud.bigquery\n","The google.colab.data_table extension is already loaded. To reload it, use:\n","  %reload_ext google.colab.data_table\n"]}]},{"cell_type":"code","source":["\n","# If using the native Google BigQuery API module:\n","from google.cloud import bigquery\n","from google.cloud.exceptions import NotFound\n","import pandas as pd\n","import os\n","import pyarrow\n","import logging\n","from datetime import datetime"],"metadata":{"id":"1dhS_W_y2-Zw","executionInfo":{"status":"ok","timestamp":1682795973011,"user_tz":240,"elapsed":8,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"id":"1dhS_W_y2-Zw","execution_count":217,"outputs":[]},{"cell_type":"code","execution_count":218,"id":"46960187","metadata":{"id":"46960187","executionInfo":{"status":"ok","timestamp":1682795973012,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["# Set the name of the dimension\n","dimension_name = 'agency'\n","\n","# Set the name of the surrogate key\n","surrogate_key = f\"{dimension_name}_dim_id\"\n","\n","# Set the name of the business key\n","business_key = f'{dimension_name}_id'\n","\n","# Set the GCP Project, dataset and table name\n","gcp_project = 'cis4400project-384418'\n","bq_dataset = 'hot_water_complaints_dw'\n","table_name = f\"{dimension_name}_dimension\"\n","# Construct the full BigQuery path to the table\n","dimension_table_path = f\"{gcp_project}.{bq_dataset}.{table_name}\"\n","\n","# Set the path to the source data files. Use double-slash for Windows paths C:\\\\myfolder\n","# For Linux use forward slashes    /home/username/python_etl \n","# For Mac use forward slashes      /users/username/python_etl\n","# file_source_path = 'c:\\\\Python_ETL'\n","# file_source_path = 'C:\\\\Users\\\\rholo\\\\OneDrive\\\\Documents\\\\classes\\\\4400\\\\311'\n","file_source_path = '/content'"]},{"cell_type":"code","execution_count":219,"id":"060f8796","metadata":{"id":"060f8796","executionInfo":{"status":"ok","timestamp":1682795973012,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["# Set up logging\n","for handler in logging.root.handlers[:]:\n","    logging.root.removeHandler(handler)\n","current_date = datetime.today().strftime('%Y%m%d')\n","log_filename = \"_\".join([\"etl\",dimension_name,current_date])+\".log\"\n","logging.basicConfig(filename=log_filename, encoding='utf-8', format='%(asctime)s %(message)s', level=logging.DEBUG)\n","logging.info(\"=========================================================================\")\n","logging.info(f\"Starting ETL Run for dimension {dimension_name} on date {current_date}\")\n"]},{"cell_type":"code","execution_count":220,"id":"bc1e72b6","metadata":{"id":"bc1e72b6","executionInfo":{"status":"ok","timestamp":1682795973013,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def load_csv_data_file(logging: logging.Logger,\n","                      file_source_path: str,\n","                      file_name: str,\n","                      df: pd.DataFrame):\n","    \"\"\"\n","    load_csv_data_file\n","    Accepts a file source path and a file name\n","    Loads the file into a data frame\n","    Exits the program on error\n","    Returns the dataframe\n","    \"\"\"\n","    file_source = os.path.join(file_source_path, file_name)\n","    logging.info(f\"Reading source data file: {file_source}\")\n","    # Read in the source data file for the customers data\n","    try:\n","        df = pd.read_csv(file_source)\n","        # Set all of the column names to lower case letters\n","        df = df.rename(columns=str.lower)\n","        logging.info(f\"Read {len(df)} records from source data file: {file_source}\")\n","        return df\n","    except:\n","        logging.error(f\"Failed to read file: {file_source}\")\n","        # os._exit(-1)\n","    return df"]},{"cell_type":"code","execution_count":221,"id":"436af56f","metadata":{"id":"436af56f","executionInfo":{"status":"ok","timestamp":1682795973014,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def transform_data(logging: logging.Logger,\n","                   df: pd.DataFrame):\n","    \"\"\"\n","    transform_data\n","    Accepts a data frame\n","    Performs any specific cleaning and transformation steps on the dataframe\n","    Returns the modified dataframe\n","    \"\"\"\n","    # Convert the date_of_birth to a datetime64 data type. 2012-08-21 04:12:16.827\n","    logging.info(\"Transforming dataframe.\")\n","    # Select the columns for this dimension\n","    column_list = ['agency','agency_name']\n","    df = df[column_list]\n","    # Remove duplicates\n","    df = df.drop_duplicates()\n","    return df"]},{"cell_type":"code","execution_count":222,"id":"0d1bee48","metadata":{"id":"0d1bee48","executionInfo":{"status":"ok","timestamp":1682795973015,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def create_bigquery_client(logging):\n","    \"\"\"\n","    create_bigquery_client\n","    Creates a BigQuery client using the path to the service account key file\n","    for credentials.\n","    Returns the BigQuery client object\n","    \"\"\"\n","    try:\n","        # bqclient = bigquery.Client.from_service_account_json(credentials.path_to_service_account_key_file)\n","        # Google Colab authentication already completed\n","        bqclient = bigquery.Client(gcp_project)\n","        logging.info(\"Created BigQuery Client: %s\",bqclient)\n","        return bqclient\n","    except Exception as err:\n","        logging.error(\"Failed to create BigQuery Client.\", err)\n","        # os._exit(-1)\n","    return bqclient\n"]},{"cell_type":"code","execution_count":223,"id":"3578f519","metadata":{"id":"3578f519","executionInfo":{"status":"ok","timestamp":1682795973015,"user_tz":240,"elapsed":9,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def upload_bigquery_table(logging, bqclient, table_path, write_disposition, df):\n","    \"\"\"\n","    upload_bigquery_table\n","    Accepts a path to a BigQuery table, the write disposition and a dataframe\n","    Loads the data into the BigQuery table from the dataframe.\n","    for credentials.\n","    The write disposition is either\n","    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.   \n","    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n","    \"\"\"\n","    try:\n","        logging.info(\"Creating BigQuery Job configuration with write_disposition=%s\", write_disposition)\n","        # Set up a BigQuery job configuration with the write_disposition.\n","        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n","        # Submit the job\n","        logging.info(\"Submitting the BigQuery job\")\n","        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)  \n","        # Show the job results\n","        logging.info(\"Job  results: %s\",job.result())\n","    except Exception as err:\n","        logging.error(\"Failed to load BigQuery Table. %s\", err)\n","        #os._exit(-1)\n"]},{"cell_type":"code","execution_count":224,"id":"3d37a312","metadata":{"id":"3d37a312","executionInfo":{"status":"ok","timestamp":1682795973143,"user_tz":240,"elapsed":137,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def bigquery_table_exists(bqclient, table_path):\n","    \"\"\"\n","    bigquery_table_exists\n","    Accepts a path to a BigQuery table\n","    Checks if the BigQuery table exists.\n","    Returns True or False\n","    \"\"\"    \n","    try:\n","        bqclient.get_table(table_path)  # Make an API request.\n","        return True\n","    except NotFound:\n","        return False"]},{"cell_type":"code","execution_count":225,"id":"79339f5c","metadata":{"id":"79339f5c","executionInfo":{"status":"ok","timestamp":1682795973143,"user_tz":240,"elapsed":4,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def query_bigquery_table(logging, table_path, bqclient, surrogate_key):\n","    \"\"\"\n","    query_bigquery_table\n","    Accepts a path to a BigQuery table and the name of the surrogate key\n","    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n","    Returns the dataframe\n","    \"\"\"    \n","    bq_df = pd.DataFrame\n","    sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n","    logging.info(\"Running query: %s\", sql_query)\n","    try:\n","        bq_df = bqclient.query(sql_query).to_dataframe()\n","    except Exception as err:\n","        logging.info(\"Error querying the table. %s\", err)\n","    return bq_df"]},{"cell_type":"code","execution_count":226,"id":"484a7699","metadata":{"id":"484a7699","executionInfo":{"status":"ok","timestamp":1682795973143,"user_tz":240,"elapsed":3,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def add_surrogate_key(df, dimension_name='customers', offset=1):\n","    \"\"\"\n","    add_surrogate_key  \n","    Accepts a data frame and inserts an integer identifier as the first column\n","    Returns the modified dataframe\n","    \"\"\"\n","    # Reset the index to count from 0\n","    df.reset_index(drop=True, inplace=True)\n","    # Add the new surrogate key starting from offset\n","    df.insert(0, dimension_name+'_dim_id', df.index+offset)\n","    return df"]},{"cell_type":"code","execution_count":227,"id":"de2d5c71","metadata":{"id":"de2d5c71","executionInfo":{"status":"ok","timestamp":1682795973144,"user_tz":240,"elapsed":4,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def add_update_date(df, current_date):\n","    \"\"\"\n","    add_update_date\n","    Accepts a data frame and inserts the current date as a new field\n","    Returns the modified dataframe\n","    \"\"\"\n","    df['update_date'] = pd.to_datetime(current_date)\n","    return df"]},{"cell_type":"code","execution_count":228,"id":"b2125588","metadata":{"id":"b2125588","executionInfo":{"status":"ok","timestamp":1682795973376,"user_tz":240,"elapsed":7,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def add_update_timestamp(df):\n","    \"\"\"\n","    add_update_timestamp\n","    Accepts a data frame and inserts the current datetime as a new field\n","    Returns the modified dataframe\n","    \"\"\"\n","    df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n","    return df"]},{"cell_type":"code","execution_count":229,"id":"a93def27","metadata":{"id":"a93def27","executionInfo":{"status":"ok","timestamp":1682795973377,"user_tz":240,"elapsed":7,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def build_new_table(logging, bqclient, dimension_table_path, dimension_name, df):\n","    \"\"\"\n","    build_new_table\n","    Accepts a path to a dimensional table, the dimension name and a data frame \n","    Add the surrogate key and a record timestamp to the data frame\n","    Inserts the contents of the dataframe to the dimensional table.\n","    \"\"\"\n","    logging.info(\"Target dimension table %s does not exit\", dimension_table_path)\n","    # Add a surrogate key\n","    df = add_surrogate_key(df, dimension_name, 1)\n","    # Add the update timestamp\n","    df = add_update_timestamp(df)\n","    # Upload the dataframe to the BigQuery table\n","    upload_bigquery_table(logging, bqclient, dimension_table_path, \"WRITE_TRUNCATE\", df)"]},{"cell_type":"code","execution_count":230,"id":"dcffe5fe","metadata":{"id":"dcffe5fe","executionInfo":{"status":"ok","timestamp":1682795973378,"user_tz":240,"elapsed":7,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["def insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df):\n","    \"\"\"\n","    insert_existing_table\n","    Accepts a path to a dimensional table, the dimension name and a data frame \n","    Compares the new data to the existing data in the table.\n","    Inserts the new/modified records to the existing table\n","    \"\"\"\n","    bq_df = pd.DataFrame\n","    logging.info(\"Target dimension table %s exits. Checking for differences.\", dimension_table_path)\n","    # Fetch the existing table\n","    bq_df = query_bigquery_table(logging, dimension_table_path, bqclient, surrogate_key)\n","    # Compare with the new data set\n","    new_records_df = pd.concat([df,bq_df]).drop_duplicates(keep=False)\n","    logging.info(\"Found %d new records.\", new_records_df.shape[0])\n","    if new_records_df.shape[0] > 0:\n","        # Set the surrogate key for the new records. bq_df.shape[0] is number of records already in the database\n","        new_surrogate_key_value = bq_df.shape[0]+1\n","        new_records_df = add_surrogate_key(new_records_df, dimension_name, new_surrogate_key_value)\n","        # Add the current date for the new records\n","        new_records_df = add_update_timestamp(new_records_df)\n","        # Upload the new records into the dimension table\n","        upload_bigquery_table(logging, bqclient, dimension_table_path, \"WRITE_APPEND\", new_records_df)    "]},{"cell_type":"code","execution_count":231,"id":"55edebde","metadata":{"scrolled":true,"id":"55edebde","executionInfo":{"status":"ok","timestamp":1682795977668,"user_tz":240,"elapsed":4297,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}}},"outputs":[],"source":["# Program main\n","# Load the CSV File into a dataframe\n","# Transform the Dataframe\n","# Create a BigQuery client\n","# See if the target dimension table exists\n","#    If not exists, load the data into a new table\n","#    If exists, insert new records into the table\n","if __name__ == \"__main__\":\n","    df = pd.DataFrame\n","    # Load in the data file\n","    df = load_csv_data_file(logging, file_source_path, \"hot_water_complaints_2020.csv\", df)\n","    # Transform the data\n","    df = transform_data(logging, df)\n","    # Create the BigQuery Client\n","    bqclient = create_bigquery_client(logging)\n","    # See if the target dimensional table exists\n","    target_table_exists = bigquery_table_exists(bqclient, dimension_table_path  )\n","    # If the target dimension table does not exist, load all of the data into a new table\n","    if not target_table_exists:\n","        build_new_table(logging, bqclient, dimension_table_path, dimension_name, df)\n","    # If the target table exists, then perform an incremental load    \n","    if target_table_exists:\n","        insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df)\n","    # Flush the log file\n","    logging.shutdown()"]},{"cell_type":"code","execution_count":232,"id":"dc79cae8","metadata":{"id":"dc79cae8","executionInfo":{"status":"ok","timestamp":1682795977670,"user_tz":240,"elapsed":36,"user":{"displayName":"justin balwan","userId":"04668427529719490580"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8590ab9-3f8b-4227-8bbf-c7423af891c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-29 19:18:44,160 http://metadata.google.internal:80 \"GET /computeMetadata/v1/instance/service-accounts/justinbalwan20@gmail.com/token?scopes=email HTTP/1.1\" 200 418\n","2023-04-29 19:18:44,208 =========================================================================\n","2023-04-29 19:18:44,208 Starting ETL Run for dimension agency on date 20230429\n","2023-04-29 19:18:44,328 Reading source data file: /content/hot_water_complaints_2022.csv\n","2023-04-29 19:18:46,397 Failed to read file: /content/hot_water_complaints_2022.csv\n","2023-04-29 19:18:46,397 Transforming dataframe.\n","2023-04-29 19:19:32,494 Making request: GET http://169.254.169.254\n","2023-04-29 19:19:32,501 Making request: GET http://metadata.google.internal/computeMetadata/v1/project/project-id\n","2023-04-29 19:19:32,504 Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\n","2023-04-29 19:19:32,505 Starting new HTTP connection (1): metadata.google.internal:80\n","2023-04-29 19:19:32,588 http://metadata.google.internal:80 \"GET /computeMetadata/v1/instance/service-accounts/default/?recursive=true HTTP/1.1\" 200 194\n","2023-04-29 19:19:32,589 Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/justinbalwan20@gmail.com/token?scopes=email\n","2023-04-29 19:19:32,657 http://metadata.google.internal:80 \"GET /computeMetadata/v1/instance/service-accounts/justinbalwan20@gmail.com/token?scopes=email HTTP/1.1\" 200 418\n","2023-04-29 19:19:32,748 =========================================================================\n","2023-04-29 19:19:32,748 Starting ETL Run for dimension agency on date 20230429\n","2023-04-29 19:19:32,886 Reading source data file: /content/hot_water_complaints_2020.csv\n","2023-04-29 19:19:35,188 Read 165573 records from source data file: /content/hot_water_complaints_2020.csv\n","2023-04-29 19:19:35,188 Transforming dataframe.\n","2023-04-29 19:19:35,290 Making request: GET http://169.254.169.254\n","2023-04-29 19:19:35,294 Making request: GET http://metadata.google.internal/computeMetadata/v1/project/project-id\n","2023-04-29 19:19:35,296 Created BigQuery Client: <google.cloud.bigquery.client.Client object at 0x7fd1d3fa9cf0>\n","2023-04-29 19:19:35,297 Converted retries value: 3 -> Retry(total=3, connect=None, read=None, redirect=None, status=None)\n","2023-04-29 19:19:35,298 Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\n","2023-04-29 19:19:35,299 Starting new HTTP connection (1): metadata.google.internal:80\n","2023-04-29 19:19:35,361 http://metadata.google.internal:80 \"GET /computeMetadata/v1/instance/service-accounts/default/?recursive=true HTTP/1.1\" 200 194\n","2023-04-29 19:19:35,362 Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/justinbalwan20@gmail.com/token?scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform\n","2023-04-29 19:19:35,418 http://metadata.google.internal:80 \"GET /computeMetadata/v1/instance/service-accounts/justinbalwan20@gmail.com/token?scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform HTTP/1.1\" 200 418\n","2023-04-29 19:19:35,419 Starting new HTTPS connection (1): bigquery.googleapis.com:443\n","2023-04-29 19:19:35,556 https://bigquery.googleapis.com:443 \"GET /bigquery/v2/projects/cis4400project-384418/datasets/hot_water_complaints_dw/tables/agency_dimension?prettyPrint=false HTTP/1.1\" 200 None\n","2023-04-29 19:19:35,557 Target dimension table cis4400project-384418.hot_water_complaints_dw.agency_dimension exits. Checking for differences.\n","2023-04-29 19:19:35,557 Running query: SELECT * EXCEPT ( update_timestamp, agency_dim_id) FROM `cis4400project-384418.hot_water_complaints_dw.agency_dimension`\n","2023-04-29 19:19:35,928 https://bigquery.googleapis.com:443 \"POST /bigquery/v2/projects/cis4400project-384418/jobs?prettyPrint=false HTTP/1.1\" 200 None\n","2023-04-29 19:19:36,163 https://bigquery.googleapis.com:443 \"GET /bigquery/v2/projects/cis4400project-384418/queries/7ec8aabd-b131-4076-bf4b-65c03e5edba7?maxResults=0&location=US&prettyPrint=false HTTP/1.1\" 200 None\n","2023-04-29 19:19:36,847 Started reading table 'cis4400project-384418._4f6c53a8efc1c2e3e7a80ee44c52a4f27c772ca9.anon0761917bbc790eac7deca48db6ce130758477c0db0fe6a3f0a100e1f50265c67' with BQ Storage API session 'projects/cis4400project-384418/locations/us/sessions/CAISDHJaYmxLeWFPQ3k0WRoCamQaAmpz'.\n","2023-04-29 19:19:37,424 Found 0 new records.\n"]}],"source":["# Check the log. Use cat, head or tail\n","!tail -35 etl_agency_20230429.log\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[{"file_id":"https://github.com/professorholowczak/Data_Warehousing/blob/main/etl_agency_dimension.ipynb","timestamp":1682785601381}]}},"nbformat":4,"nbformat_minor":5}